{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Import data\n",
        "import pandas as pd\n",
        "Data = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "1hiY97MEzwgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Drop the rows that are not needed (have missing status values) as sensitive data so we can't fill it with mean or mode\n",
        "Data.dropna(subset=['Age'], inplace=True)\n",
        "Data.dropna(subset=['Gender'], inplace=True)\n",
        "Data.dropna(subset=['BMI'], inplace=True)\n",
        "Data.dropna(subset=['SBP'], inplace=True)\n",
        "Data.dropna(subset=['DBP'], inplace=True)\n",
        "Data.dropna(subset=['FPG'], inplace=True)\n",
        "Data.dropna(subset=['Chol'], inplace=True)\n",
        "Data.dropna(subset=['Tri'], inplace=True)\n",
        "Data.dropna(subset=['HDL'], inplace=True)\n",
        "Data.dropna(subset=['LDL'], inplace=True)\n",
        "Data.dropna(subset=['ALT'], inplace=True)\n",
        "Data.dropna(subset=['BUN'], inplace=True)\n",
        "Data.dropna(subset=['CCR'], inplace=True)\n",
        "Data.dropna(subset=['FFPG'], inplace=True)\n",
        "Data.dropna(subset=['Smoking'], inplace=True)\n",
        "Data.dropna(subset=['Drinking'], inplace=True)\n",
        "Data.dropna(subset=['Family_histroy'], inplace=True)\n",
        "Data.dropna(subset=['Diabetes'], inplace=True)"
      ],
      "metadata": {
        "id": "q-FsdKt4z1x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Convert necessery column to numeric\n",
        "Data['Age'] = pd.to_numeric(Data['Age'], errors='coerce')\n",
        "Data['Gender'] = pd.to_numeric(Data['Gender'], errors='coerce')\n",
        "Data['BMI'] = pd.to_numeric(Data['BMI'], errors='coerce')\n",
        "Data['SBP'] = pd.to_numeric(Data['SBP'], errors='coerce')\n",
        "Data['DBP'] = pd.to_numeric(Data['DBP'], errors='coerce')\n",
        "Data['FPG'] = pd.to_numeric(Data['FPG'], errors='coerce')\n",
        "Data['Chol'] = pd.to_numeric(Data['Chol'], errors='coerce')\n",
        "Data['Tri'] = pd.to_numeric(Data['Tri'], errors='coerce')\n",
        "Data['HDL'] = pd.to_numeric(Data['HDL'], errors='coerce')\n",
        "Data['LDL'] = pd.to_numeric(Data['LDL'], errors='coerce')\n",
        "Data['ALT'] = pd.to_numeric(Data['ALT'], errors='coerce')\n",
        "Data['BUN'] = pd.to_numeric(Data['BUN'], errors='coerce')\n",
        "Data['CCR'] = pd.to_numeric(Data['CCR'], errors='coerce')\n",
        "Data['FFPG'] = pd.to_numeric(Data['FFPG'], errors='coerce')\n",
        "Data['Smoking'] = pd.to_numeric(Data['Smoking'], errors='coerce')\n",
        "Data['Drinking'] = pd.to_numeric(Data['Drinking'], errors='coerce')\n",
        "Data['Family_histroy'] = pd.to_numeric(Data['Family_histroy'], errors='coerce')\n",
        "Data['Diabetes'] = pd.to_numeric(Data['Diabetes'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "2w5lvruSz48M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Drop the duplicate rows\n",
        "Data.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "No9MBWw3z7PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Information of Dataset\n",
        "Data.info()\n"
      ],
      "metadata": {
        "id": "1oCBq_K5z8jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Data describe\n",
        "Data.describe()"
      ],
      "metadata": {
        "id": "TWZvt44wz_sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Data Groupping\n",
        "print(Data.groupby('Diabetes').size())"
      ],
      "metadata": {
        "id": "WCZ43wAI0QvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. let's visualise the number of samples for each class with count plot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.countplot(x='Diabetes', data=Data)\n",
        "plt.title('Number of samples for each class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aF6dVdTP0U7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Calculate the correlation matrix\n",
        "from matplotlib import pyplot\n",
        "corr_matrix = Data.corr()\n",
        "fig, ax = pyplot.subplots(figsize=(30, 20))\n",
        "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, ax=ax)\n",
        "ax.set_title('Correlation Matrix')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "_G3uchBL1EQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Feature matrix\n",
        "X = Data[['Age', 'Gender', 'BMI', 'SBP','DBP','FPG','Chol', 'Tri','HDL', 'LDL','ALT','BUN','CCR', 'FFPG','Smoking','Drinking', 'Family_histroy']]\n",
        "print(\"----------------- Feature Matrix -----------------\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "id": "sPeAqhvP1Igc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Target Matrix\n",
        "y = Data['Diabetes']\n",
        "print(\"----------------- Target Matrix -----------------\")\n",
        "print(y.head())"
      ],
      "metadata": {
        "id": "gA4l4BgT1L5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Model Training and Testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.28, random_state=16)\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ],
      "metadata": {
        "id": "S0eeXAqE1R8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Define classifier\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_svm = svm.SVC()\n",
        "model_nb = GaussianNB()\n",
        "model_knn = KNeighborsClassifier()\n",
        "model_lr = LogisticRegression()\n",
        "model_dt = DecisionTreeClassifier()\n"
      ],
      "metadata": {
        "id": "TGIXx-5P1Uke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Train using this classifier\n",
        "model_svm.fit(X_train, y_train)\n",
        "model_nb.fit(X_train, y_train)\n",
        "model_knn.fit(X_train, y_train)\n",
        "model_lr.fit(X_train, y_train)\n",
        "model_dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "f4-YCpq_1ZEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Test Classifier\n",
        "from sklearn import metrics\n",
        "score = {}\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "score_svm = metrics.accuracy_score(y_test, y_pred_svm).round(5)\n",
        "score[\"SVM\"] = score_svm\n",
        "\n",
        "y_pred_nb = model_nb.predict(X_test)\n",
        "score_nb = metrics.accuracy_score(y_test, y_pred_nb).round(5)\n",
        "score[\"Naive Bayes\"] = score_nb\n",
        "\n",
        "y_pred_knn = model_knn.predict(X_test)\n",
        "score_knn = metrics.accuracy_score(y_test, y_pred_knn).round(5)\n",
        "score[\"KNN\"] = score_knn\n",
        "\n",
        "y_pred_lr = model_lr.predict(X_test)\n",
        "score_lr = metrics.accuracy_score(y_test, y_pred_lr).round(5)\n",
        "score[\"Logistic Regression\"] = score_lr\n",
        "\n",
        "y_pred_dt = model_dt.predict(X_test)\n",
        "score_dt = metrics.accuracy_score(y_test, y_pred_dt).round(5)\n",
        "score[\"Decision Tree\"] = score_dt"
      ],
      "metadata": {
        "id": "-aIyujYt1ppX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Predict Classifier Accuracy\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "score_svm = metrics.accuracy_score(y_test, y_pred_svm).round(5)\n",
        "score[\"SVM\"] = score_svm\n",
        "\n",
        "y_pred_nb = model_nb.predict(X_test)\n",
        "score_nb = metrics.accuracy_score(y_test, y_pred_nb).round(5)\n",
        "score[\"Naive Bayes\"] = score_nb\n",
        "\n",
        "y_pred_knn = model_knn.predict(X_test)\n",
        "score_knn = metrics.accuracy_score(y_test, y_pred_knn).round(5)\n",
        "score[\"KNN\"] = score_knn\n",
        "\n",
        "y_pred_lr = model_lr.predict(X_test)\n",
        "score_lr = metrics.accuracy_score(y_test, y_pred_lr).round(5)\n",
        "score[\"Logistic Regression\"] = score_lr\n",
        "\n",
        "y_pred_dt = model_dt.predict(X_test)\n",
        "score_dt = metrics.accuracy_score(y_test, y_pred_dt).round(5)\n",
        "score[\"Decision Tree\"] = score_dt"
      ],
      "metadata": {
        "id": "7bKoPa-N10eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Fianl Accuracy Result\n",
        "data = {\n",
        "    \"Models\": ['SVM','Naive Bayes','KNN','Logistic Regression','Decision Tree'],\n",
        "    \"Accuracy(%)\": [score_svm*100,score_nb*100,score_knn*100,score_lr*100,score_dt*100]\n",
        "}\n",
        "score_df = pd.DataFrame(data)\n",
        "print(score_df)"
      ],
      "metadata": {
        "id": "NxpVizQ118zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Best Accuracy algorithm\n",
        "max=0\n",
        "Bkey=''\n",
        "Bvalue=0\n",
        "for key, value in score.items():\n",
        "    #print(key, \":\", value)\n",
        "    if(value>max):\n",
        "      max=value\n",
        "      Bkey=key\n",
        "      Bvalue=value\n",
        "print(\"Best Accuracy Algorithm For Model is\",Bkey,\" =\",Bvalue*100,\" %\")\n"
      ],
      "metadata": {
        "id": "UUtGUUvw2AS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Calculate Confusion Matrix for SVM\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model_svm.fit(X_train, y_train)\n",
        "predictions_svm = model_svm.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions_svm)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(\"Total Instance: \", tp+tn+fp+fn)\n"
      ],
      "metadata": {
        "id": "d8oDDOcg2JT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Calculate Confusion Matrix for NB\n",
        "model_nb.fit(X_train, y_train)\n",
        "predictions_nb = model_nb.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions_nb)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(\"Total Instance: \", tp+tn+fp+fn)"
      ],
      "metadata": {
        "id": "tQigrPxU4tAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Calculate Confusion Matrix for KNN\n",
        "model_knn.fit(X_train, y_train)\n",
        "predictions_knn = model_knn.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions_knn)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(\"Total Instance: \", tp+tn+fp+fn)"
      ],
      "metadata": {
        "id": "-ipg6l9l-l_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Calculate Confusion Matrix for DT\n",
        "model_dt.fit(X_train, y_train)\n",
        "predictions_dt = model_dt.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions_dt)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(\"Total Instance: \", tp+tn+fp+fn)"
      ],
      "metadata": {
        "id": "0lnNRRw4-sG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Calculate Confusion Matrix for LR\n",
        "model_lr.fit(X_train, y_train)\n",
        "predictions_lr = model_lr.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions_lr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(\"Total Instance: \", tp+tn+fp+fn)"
      ],
      "metadata": {
        "id": "Vo-TpJ29-vvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Accuracy, Precision, Recall, F-Measure\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f_measure_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb)\n",
        "recall_nb = recall_score(y_test, y_pred_nb)\n",
        "f_measure_nb = f1_score(y_test, y_pred_nb)\n",
        "\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn)\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "f_measure_knn = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr)\n",
        "recall_lr = recall_score(y_test, y_pred_lr)\n",
        "f_measure_lr = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f_measure_dt = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"------SVM--------\")\n",
        "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
        "print(f\"Precision: {precision_svm:.4f}\")\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "print(f\"F-Measure: {f_measure_svm:.4f}\")\n",
        "\n",
        "print(\"------NB--------\")\n",
        "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
        "print(f\"Precision: {precision_nb:.4f}\")\n",
        "print(f\"Recall: {recall_nb:.4f}\")\n",
        "print(f\"F-Measure: {f_measure_nb:.4f}\")\n",
        "\n",
        "print(\"------KNN--------\")\n",
        "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
        "print(f\"Precision: {precision_knn:.4f}\")\n",
        "print(f\"Recall: {recall_knn:.4f}\")\n",
        "print(f\"F-Measure: {f_measure_knn:.4f}\")\n",
        "\n",
        "print(\"------LR--------\")\n",
        "print(f\"Accuracy: {accuracy_lr:.4f}\")\n",
        "print(f\"Precision: {precision_lr:.4f}\")\n",
        "print(f\"Recall: {recall_lr:.4f}\")\n",
        "print(f\"F-Measure: {f_measure_lr:.4f}\")\n",
        "\n",
        "print(\"------DT--------\")\n",
        "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Precision: {precision_dt:.4f}\")\n",
        "print(f\"Recall: {recall_dt:.4f}\")\n",
        "print(f\"F-Measure: {f_measure_dt:.4f}\")"
      ],
      "metadata": {
        "id": "And418Ra2nWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25.Calculate ROC Curve\n",
        "fpr1, tpr1, _ = roc_curve(y_test, y_pred_svm)  # Thresholds (ignored)\n",
        "roc_auc1 = auc(fpr1, tpr1)\n",
        "fpr2, tpr2, _ = roc_curve(y_test, y_pred_nb)\n",
        "roc_auc2 = auc(fpr2, tpr2)\n",
        "fpr3, tpr3, _ = roc_curve(y_test, y_pred_knn)\n",
        "roc_auc3 = auc(fpr3, tpr3)\n",
        "fpr4, tpr4, _ = roc_curve(y_test, y_pred_dt)\n",
        "roc_auc4 = auc(fpr4, tpr4)\n",
        "fpr5, tpr5, _ = roc_curve(y_test, y_pred_lr)\n",
        "roc_auc5 = auc(fpr5, tpr5)"
      ],
      "metadata": {
        "id": "3HJYt-yZ2rnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 26. Plot ROC Curve SVM\n",
        "plt.figure()\n",
        "plt.plot(fpr1, tpr1, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc1)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lnnGb7G823s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 27. Plot ROC Curve NB\n",
        "plt.figure()\n",
        "plt.plot(fpr2, tpr2, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc2)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PlstHpZG3HhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 28. Plot ROC Curve KNN\n",
        "plt.figure()\n",
        "plt.plot(fpr3, tpr3, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc3)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "REhzW2w-3ci4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 29. Plot ROC Curve DT\n",
        "plt.figure()\n",
        "plt.plot(fpr4, tpr4, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc4)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zOV3ZWOe3fxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30. Plot ROC Curve LR\n",
        "plt.figure()\n",
        "plt.plot(fpr5, tpr5, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc5)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tdCXSVSl30px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 31. Chart\n",
        "data = {'Algorithm': ['NB', 'SVM', 'DT', 'KNN', 'LR'],\n",
        "        'Precision': [0.9140, 0.8152, 0.8920, 0.6715, 0.9443],\n",
        "        'Recall': [0.886, 0.688, 0.8969, 0.5181, 0.8496],\n",
        "        'F-Measure': [0.9011, 0.7462, 0.8944, 0.5849, 0.8944],\n",
        "        'Accuracy%': [0.9419, 0.8606, 0.9369, 0.7809, 0.9402]}\n",
        "\n",
        "plt.bar(data['Algorithm'], data['Precision'])\n",
        "plt.xlabel('Classifiers')\n",
        "plt.ylabel('Range')\n",
        "plt.title('Precision')\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "plt.bar(data['Algorithm'], data['Recall'])\n",
        "plt.xlabel('Classifiers')\n",
        "plt.ylabel('Range')\n",
        "plt.title('Recall')\n",
        "plt.show()\n",
        "print()\n",
        "plt.bar(data['Algorithm'], data['F-Measure'])\n",
        "plt.xlabel('Classifiers')\n",
        "plt.ylabel('Range')\n",
        "plt.title('F-Measure')\n",
        "plt.show()\n",
        "print()\n",
        "plt.bar(data['Algorithm'], data['Accuracy%'])\n",
        "plt.xlabel('Classifiers')\n",
        "plt.ylabel('Range')\n",
        "plt.title('Accuracy%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GPH0bsAeQbwC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}